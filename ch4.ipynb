{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4b23f7-bde9-469d-a954-eb1e44447337",
   "metadata": {},
   "source": [
    "Let's start by defining the configuration a small GPT2 model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eae06e-9cdd-4f66-8385-6b94e0dc00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12, # attention heads\n",
    "    \"n_layers\": 12, # transformer layers\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ead86-4f5c-4623-b7d0-044078f1409f",
   "metadata": {},
   "source": [
    "Now we'll build a skeleton for the GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a689b-e79c-4be7-bcc2-af90b2d41619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(*[DummyTransformerBlock(cfg)\n",
    "                                          for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        # seq_len == context_len, right?\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "\n",
    "        # 1. embed\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "\n",
    "        # 2. transformer blocks\n",
    "        x = self.trf_blocks(x)\n",
    "\n",
    "        # 3. output layers\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589d920-5c10-4b2b-8967-84aaa67fd323",
   "metadata": {},
   "source": [
    "Ok, we're wiring up everything! So we need to tokenize input such that it can be passed into the GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbebe3f8-8264-48e8-8dc9-07112acb9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of tensors:\n",
      "[tensor([6109, 3626, 6100,  345]), tensor([6109, 1110, 6622,  257])]\n",
      "stacked:\n",
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "print(\"list of tensors:\")\n",
    "print(batch)\n",
    "\n",
    "print(\"stacked:\")\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28d5f07-8169-40cf-8f21-cc2446d3b4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output logits.shape torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"output logits.shape\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69899909-ec02-4688-99b8-18efd57ad329",
   "metadata": {},
   "source": [
    "### Layer Normalization\n",
    "\n",
    "Let's explore the behavior of layer normalization, then add it to our GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b23ecc-8c52-4d8a-aa61-52f1601440cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_example:\n",
      " tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
      "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])\n",
      "out:\n",
      " tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2,5)\n",
    "print(\"batch_example:\\n\", batch_example)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(\"out:\\n\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e9bcf1-a1d2-4fa1-b706-31387f298526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40afb353-82b5-4345-8e64-ed6f87bd3397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out-mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aae5645-dcdf-4ede-b030-e149d3a37e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e8176-2d5c-4b9d-b861-14b936738d97",
   "metadata": {},
   "source": [
    "So the basic idea was:\n",
    "1. subtract the mean from each item -> gets us to mean of 0\n",
    "2. divide by the std dev -> gets us to variance of 1\n",
    "\n",
    "Let's now encode this as a reusable class. We'll also add some trainable weights for `shift` and `scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410ff78-3c7d-452f-9469-fccbb1d19489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim)) # 1 is mult identity\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) # 0 is add identity\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (1) normalize\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        # NOTE: unbiased=False mirrors GPT2 implementation,\n",
    "        # which was in Tensorflow where that's the default\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased = False)\n",
    "        # NOTE: We include eps as a small constant to prevent division by zero\n",
    "        norm_x = (x-mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "        # (2) shift and scale\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d63cdd-b2d4-4146-a19a-acef29aa9c77",
   "metadata": {},
   "source": [
    "Let's try out LayerNorm usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24a1727-c83b-450d-8291-19aeb7990248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9abf145-12fa-41c7-88cc-2d0ea4b1fc3e",
   "metadata": {},
   "source": [
    "### GELU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31550fde-273d-4ae3-837d-19ea67e0b686",
   "metadata": {},
   "source": [
    "OK! Let's now implement GELU, which will be used within the FeedForward module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f9666-7006-47b1-9342-8e861cf17e80",
   "metadata": {},
   "source": [
    "$$\n",
    "GELU(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot (x + 0.044715 \\cdot x^3)\\right]\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e866f5-4a9a-4ea6-ac21-89c825ad98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd28fd-381b-400c-8053-705a1cd5ce98",
   "metadata": {},
   "source": [
    "To get more intuition into GELU (Gaussian error linear unit), let's plot it side by side with ReLU (Rectified Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5178182-87d4-41dd-833d-e4dea043a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034c399f-aaa1-4f1c-9cbf-404cefc6904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(-3, 3, 100) # samples 100 data pts in range -3 to 3\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8,3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1,2,i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activiation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e181b-9048-43aa-9c00-80332a3e0875",
   "metadata": {},
   "source": [
    "GELU \n",
    "- is smooth, which can lead to better optimization during training. \n",
    "- has a non-zero gradient everywhere except approx `-0.75`.\n",
    "- has non-zero values for `x<0`, which means it can still play a small role in learning\n",
    "\n",
    "ReLU has a sharp corner at zero, which can sometimes make optimization harder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb794574-542e-46fc-b708-b50fc90400e3",
   "metadata": {},
   "source": [
    "### Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6da46-3000-484e-babf-d6efea4db441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Refactor so it takes actual args intead of cfg\n",
    "# This would be consistent with our other modules\n",
    "# and keeps untyped cfg dict at outermost interface, only\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b62cfb1c-013a-4419-b99e-2dc1003588cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "samples = 2 # batch size\n",
    "tokens = 3\n",
    "x = torch.rand(samples, tokens, GPT_CONFIG_124M[\"emb_dim\"])\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f269951d-cac6-4271-9257-0e6a7dfa199c",
   "metadata": {},
   "source": [
    "### Shortcut connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426e52a-7f02-42cb-ad83-90b4cefd8dbe",
   "metadata": {},
   "source": [
    "Let's first build a simple DNN with shortcut connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d424f9-3fc9-4d47-b0b1-4220c2c0a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDNN(nn.Module):\n",
    "    def __init__(self, layer_size: list[int], use_shortcut: bool):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            out = layer(x)\n",
    "            # if enabled AND applicable\n",
    "            if self.use_shortcut and x.shape == out.shape:\n",
    "                x = x + out\n",
    "            else:\n",
    "                x = out\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda6a45c-b1ec-49f6-8016-63226c84f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3,3,3,3,3,1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDNN(layer_sizes, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca10826-ce2e-432b-a63b-b4383e13331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x) # forward pass\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target) # compute loss\n",
    "\n",
    "    loss.backward() # backward pass, to calculate gradients\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c322283e-0569-4f64-8825-0b8628bbc695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
      "layers.3.0.weight has gradient mean of 0.0013988735154271126\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aa00b8b-dc35-4ef3-b921-ee0d627d5027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDNN(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cca086-579c-4d1d-9c29-8738ad8a84c3",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425f510-63ff-4764-bb89-913ee8283f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## copied from Ch3\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout: float, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            f\"d_out ({d_out}) must be divisible by num_heads ({num_heads})\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # Linear layer to combine head outputs\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # b is number inputs in a batch\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        # after multiplying by weights, the shape of these is:\n",
    "        # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # view() aka \"reshape\"\n",
    "        # We can think of this as breaking up the single matrix into multiple, one per head (num_heads)\n",
    "        # recall that `d_out = num_heads * head_dim`\n",
    "        # after running view(), the new dimensions are: (b, num_tokens, num_heads, head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # transpose results in shape\n",
    "        # before: (b, num_tokens, num_heads, head_dim)\n",
    "        #                 ->\n",
    "        # after:  (b, num_heads, num_tokens, head_dim)\n",
    "        queries = queries.transpose(1,2)\n",
    "        keys = keys.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "\n",
    "        # 1st, we called .T\n",
    "        # 2nd, we called .transpose(1,2) to handle batches (idx=0)\n",
    "        # now, we call   .transpose(2,3) to handle batches (idx=0) with multiple heads (idx=1)\n",
    "        attn_scores = queries @ keys.transpose(2,3)\n",
    "\n",
    "        # apply mask for causal attention\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        # normalize\n",
    "        d_k = keys.shape[-1]\n",
    "        attn_weights = torch.softmax(attn_scores / d_k**0.5, dim=-1)\n",
    "\n",
    "        # dropout\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # compute context vector\n",
    "        #\n",
    "        # we transpose to convert from:\n",
    "        # before: (b, num_heads, num_tokens, head_dim)\n",
    "        #     ->\n",
    "        # after: (b, num_tokens, n_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1,2)\n",
    "\n",
    "        # combine the heads\n",
    "        # before: (b, num_heads, num_tokens, head_dim)\n",
    "        #     ->\n",
    "        # after: (b, num_tokens, d_out)\n",
    "        #                        d_out = num_tokens * head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "\n",
    "        # combine the heads through a linear layer\n",
    "        # this is considered optional... why?\n",
    "        # TODO: appendix B for more details\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fbd1b7-007c-469c-b7eb-20fdc310e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm_1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.mha = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"],\n",
    "        )\n",
    "        self.dropout_1 = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.layer_norm_2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.dropout_2 = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut1 = x\n",
    "        x = self.layer_norm_1(x)\n",
    "        x = self.mha(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = x + shortcut1\n",
    "\n",
    "        shortcut2 = x\n",
    "        x = self.layer_norm_1(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = x + shortcut2\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2188d3f-5b1c-451b-9622-1ba123c25cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([2, 4, 768])\n",
      "Output shape torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "tf_block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = tf_block(x)\n",
    "\n",
    "print(\"Input shape\", x.shape)\n",
    "print(\"Output shape\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05df63-7f41-4293-8b0d-e7245420d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg: dict):\n",
    "        super().__init__()\n",
    "\n",
    "        ## (1) Input -> Embeddings ##\n",
    "        # token embedding\n",
    "        self.token_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        # positional embedding\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        # dropout\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        ## (2) Transformers ##\n",
    "        # 12x transformer blocks\n",
    "        self.tf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "\n",
    "        ## (3) Embeddings -> Output ##\n",
    "        # layer norm\n",
    "        self.final_layer_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "\n",
    "        # linear output layer (convert back to vocab)\n",
    "        self.linear_output = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, context_length = x.shape\n",
    "\n",
    "        # `tok_emb` should be initialized randomly, so we just need to do the lookup\n",
    "        tok_embedding = self.token_emb(x)\n",
    "        # `pos_emb` should be initialized based on ordered position\n",
    "        # TODO: what does it mean that we call this during the forward() step?\n",
    "        #       intuitively, I think of pos_emb as initialized at start and then updated at each step\n",
    "        pos_embedding = self.pos_emb(torch.arange(context_length, device=x.device))\n",
    "        x = tok_embedding + pos_embedding\n",
    "        x = self.drop_emb(x)\n",
    "\n",
    "\n",
    "        x = self.tf_blocks(x)\n",
    "\n",
    "        x = self.final_layer_norm(x)\n",
    "        logits = self.linear_output(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee618762-6e1c-4b84-9a87-975c8e5ea2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4223, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ddec7f9-fb60-4ca4-b3e9-3fecde9c4898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 163009536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dffb7bf3-3935-47c3-8ce6-ac3129e67ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.token_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.linear_output.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fe83a74-c80c-46e3-9653-71c3014498bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 params = 124412160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt = total_params - sum(p.numel() for p in model.linear_output.parameters())\n",
    "print(f\"GPT2 params =\", total_params_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3fb2f-9a70-421a-ac4b-bd5fffef520d",
   "metadata": {},
   "source": [
    "**Weight Tying**\n",
    "\n",
    "Why the diference between 163M total parameters above vs 124M in the GPT model name?\n",
    "\n",
    "The original GPT-2 model re-used the same weights between the Token Embedding (Vocab -> Token Embed) and Output Layer (Token Embed -> Vocab).\n",
    "\n",
    "This is called \"Weight tying\", and it reduces the memory footprint by reducing the number of weights which are trained.\n",
    "However, it has been found to improve performance if we *don't* use weight tying, so modern models no longer use this approach.\n",
    "\n",
    "p.s. We'll revisit this concept in Ch6 when we use pretrained weights from OpenAI, since we'll want to fully reproduce their architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56788bfb-cc8e-4ea4-9ad0-c4b7dc1dce75",
   "metadata": {},
   "source": [
    "_Ex 4.1: Calculate and compare the number of parameters that are contained in the feed forward module and those that are contained in the multi-head attention module._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afca9687-76c9-4b6e-9988-96541c3b735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed forward module params: 4,722,432\n",
      "Multi-head attention module params: 2,360,064\n"
     ]
    }
   ],
   "source": [
    "get_param_count = lambda model: sum(p.numel() for p in model.parameters())\n",
    "\n",
    "example_tf = TransformerBlock(GPT_CONFIG_124M)\n",
    "print(f\"Feed forward module params: {get_param_count(example_tf.ff):,}\")\n",
    "print(f\"Multi-head attention module params: {get_param_count(example_tf.mha):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb0726-697c-4e85-976a-71f93f693b77",
   "metadata": {},
   "source": [
    "Let's also compute the memory requirements of the 163M parameters in our model.\n",
    "Assuming 4Kb per float..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf383d3c-4197-4e07-a9d0-34458dda7b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint of 163,009,536 parameter model: 621.83 Mb\n"
     ]
    }
   ],
   "source": [
    "bytes_per_float = 4 # 32-bit float\n",
    "total_bytes = total_params * bytes_per_float\n",
    "total_mb = total_bytes / (1024 * 1024)\n",
    "print(f\"Memory footprint of {total_params:,} parameter model: {total_mb:.2f} Mb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ece8b-807a-48b7-8e65-d4d5f51f5794",
   "metadata": {},
   "source": [
    "_Exercise 4.2 Initializing larger GPT models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61281cb3-7a84-4a23-b962-32adab07d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_MEDIUM = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 1024,\n",
    "    \"n_heads\": 16, # attention heads\n",
    "    \"n_layers\": 24, # transformer layers\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "GPT_CONFIG_LARGE = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 1280,\n",
    "    \"n_heads\": 20, # attention heads\n",
    "    \"n_layers\": 36, # transformer layers\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "GPT_CONFIG_XLARGE = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 1600,\n",
    "    \"n_heads\": 25, # attention heads\n",
    "    \"n_layers\": 48, # transformer layers\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ab991ea-886b-45a0-8afa-be5a3e9c912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT M  param count = 406,212,608\n",
      "GPT L  param count = 838,220,800\n",
      "GPT XL param count = 1,637,792,000\n"
     ]
    }
   ],
   "source": [
    "gpt_m = GPTModel(GPT_CONFIG_MEDIUM)\n",
    "gpt_l = GPTModel(GPT_CONFIG_LARGE)\n",
    "gpt_xl = GPTModel(GPT_CONFIG_XLARGE)\n",
    "\n",
    "print(f\"GPT M  param count = {get_param_count(gpt_m):,}\")\n",
    "print(f\"GPT L  param count = {get_param_count(gpt_l):,}\")\n",
    "print(f\"GPT XL param count = {get_param_count(gpt_xl):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af8cdf6-bd67-46e4-b248-8907b8c5ab3b",
   "metadata": {},
   "source": [
    "### Generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece739e-ba81-4e16-bbdb-698aec466a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, token_ids, max_new_tokens, context_size):\n",
    "    for i in range(max_new_tokens):\n",
    "        # all samples in batch .. most-recent `<= context_size` tokens\n",
    "        x = token_ids[:, -context_size:]\n",
    "        with torch.no_grad(): # during inference, we don't need backprop\n",
    "            logits = model(x)\n",
    "\n",
    "        token = next_token_id(logits)\n",
    "        print(\"token_ids\", token_ids)\n",
    "        print(\"token_ids.shape\", token_ids.shape)\n",
    "\n",
    "        print(\"token\", token)\n",
    "        print(\"token.shape\", token.shape)\n",
    "        print(\"\")\n",
    "        token_ids = torch.cat((token_ids, token), dim=1)\n",
    "\n",
    "    return token_ids\n",
    "\n",
    "def next_token_id(batch_logits):\n",
    "    \"\"\" Given batched model output,\n",
    "        return next token's id  \"\"\"\n",
    "    # for each sample in batch, select logits for last token\n",
    "    last_token_logits = batch_logits[:, -1, :]\n",
    "\n",
    "    # softmax to get probabilities\n",
    "    probas = torch.softmax(last_token_logits, dim=-1)\n",
    "\n",
    "    # argmax to choose most likely probability\n",
    "    token_id = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "    return token_id\n",
    "\n",
    "    # lookup corresponding token ID, convert to text\n",
    "    # return tokenizer.decode(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8254bf91-bd10-4c1c-b63c-faad96360001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) # unsqueeze adds batch dimension\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1836999a-bd6f-4348-9ab7-9cb45068f512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids tensor([[15496,    11,   314,   716]])\n",
      "token_ids.shape torch.Size([1, 4])\n",
      "token tensor([[27018]])\n",
      "token.shape torch.Size([1, 1])\n",
      "\n",
      "token_ids tensor([[15496,    11,   314,   716, 27018]])\n",
      "token_ids.shape torch.Size([1, 5])\n",
      "token tensor([[24086]])\n",
      "token.shape torch.Size([1, 1])\n",
      "\n",
      "token_ids tensor([[15496,    11,   314,   716, 27018, 24086]])\n",
      "token_ids.shape torch.Size([1, 6])\n",
      "token tensor([[47843]])\n",
      "token.shape torch.Size([1, 1])\n",
      "\n",
      "token_ids tensor([[15496,    11,   314,   716, 27018, 24086, 47843]])\n",
      "token_ids.shape torch.Size([1, 7])\n",
      "token tensor([[30961]])\n",
      "token.shape torch.Size([1, 1])\n",
      "\n",
      "token_ids tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961]])\n",
      "token_ids.shape torch.Size([1, 8])\n",
      "token tensor([[42348]])\n",
      "token.shape torch.Size([1, 1])\n",
      "\n",
      "token_ids tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348]])\n",
      "token_ids.shape torch.Size([1, 9])\n",
      "token tensor([[7267]])\n",
      "token.shape torch.Size([1, 1])\n",
      "\n",
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() # disables dropout layers. allows proper inference()\n",
    "out = generate_text_simple(model, encoded_tensor, 6, GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21442345-8d0c-4041-b1ca-b705c7225ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16bd08-d41d-410d-8871-c7b9f9b18791",
   "metadata": {},
   "source": [
    "The output isn't meaningful because we haven't trained the model! \n",
    "So that's our next task in Ch 5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c82dd-c420-4d27-8976-a103987d5b69",
   "metadata": {},
   "source": [
    "_Exercise 4.3 Using separate dropout parameters_\n",
    "\n",
    "-> Skipping, since seems straightforward via refactoring config and how it gets passed to model components. If we plan to use it later, can do so."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
