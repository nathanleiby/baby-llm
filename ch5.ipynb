{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b2b461",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Chapter 5: Pretraining on Unlabeled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fedcf9",
   "metadata": {},
   "source": [
    "### 5.1 Evaluating Generate Text models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3f5fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (tf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer_norm): LayerNorm()\n",
       "  (linear_output): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from core import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256, # we use a shorer context length to make it easier to train on a laptop\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8da065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from core import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # unsqueeze to add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # squeeze to remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model,\n",
    "    text_to_token_ids(start_context, tokenizer),\n",
    "    10,\n",
    "    GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b036e63",
   "metadata": {},
   "source": [
    "Let's try calculating the loss for some small text snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2553557",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da31efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])  #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c6282ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probas shape: torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"Probas shape:\", probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c92c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c538d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdeccb2",
   "metadata": {},
   "source": [
    "Ok, so clearly it's wrong, but how do we get to loss? \n",
    "\n",
    "First let's see the computed \"target probabilities\", i.e. \"What probability the model assigns to the correct word\"?\n",
    "\n",
    "Then we can calculate the loss as the negative log of the target probability of the correct word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c997bb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 target probabilities: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2 target probabilites: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, range(3), targets[text_idx]]\n",
    "print(\"Text 1 target probabilities:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, range(3), targets[text_idx]]\n",
    "print(\"Text 2 target probabilites:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816cb1",
   "metadata": {},
   "source": [
    "The baseline probabilities here are about equal to `1 / (vocab size)`, which is 1/50257. \n",
    "The model is not trained yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4107f1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e706f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_prob = torch.mean(log_probas)\n",
    "neg_avg_prob = -avg_prob\n",
    "print(\"Loss:\", neg_avg_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab7b73",
   "metadata": {},
   "source": [
    "This process to get loss can be handled more simply via the built in \"Cross Entropy Loss\" function in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d55e43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ed7e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits shape: torch.Size([6, 50257])\n",
      "Flattened targets shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# combine over the batch dimension\n",
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits shape:\", logits_flat.shape)\n",
    "print(\"Flattened targets shape:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "661f3f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy loss: tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\"Cross-entropy loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e6deca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity:\", torch.exp(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b62c83",
   "metadata": {},
   "source": [
    "Next up: computing training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "232bf9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cd13772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Total characters:\", total_characters)\n",
    "print(\"Total tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "562e4ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      " I HAD always thought Jack Gisburn rather a cheap g ...  and watched me, the thing they called my 'techniq\n",
      "Val data:\n",
      " ue' collapsed like a house of cards. He didn't sneer, you understand, poor Stroud--he just lay there quietly watching, and on his lips, through the gray beard, I seemed to hear the question: 'Are you sure you know where you're coming out?'\n",
      "\n",
      "\"If I could have painted that face, with that question on it, I should have done a great thing. The next greatest thing was to see that I couldn't--and that grace was given me. But, oh, at that minute, Rickham, was there anything on earth I wouldn't have given to have Stroud alive before me, and to hear him say: 'It's not too late--I'll show you how'?\n",
      "\n",
      "\"It _was_ too late--it would have been, even if he'd been alive. I packed up my traps, and went down and told Mrs. Stroud. Of course I didn't tell her _that_--it would have been Greek to her. I simply said I couldn't paint him, that I was too moved. She rather liked the idea--she's so romantic! It was that that made her give me the donkey. But she was terribly upset at not getting the portrait--she did so want him 'done' by some one showy! At first I was afraid she wouldn't let me off--and at my wits' end I suggested Grindle. Yes, it was I who started Grindle: I told Mrs. Stroud he was the 'coming' man, and she told somebody else, and so it got to be true. . . . And he painted Stroud without wincing; and she hung the picture among her husband's things. . . .\"\n",
      "\n",
      "He flung himself down in the arm-chair near mine, laid back his head, and clasping his arms beneath it, looked up at the picture above the chimney-piece.\n",
      "\n",
      "\"I like to fancy that Stroud himself would have given it to me, if he'd been able to say what he thought that day.\"\n",
      "\n",
      "And, in answer to a question I put half-mechanically--\"Begin again?\" he flashed out. \"When the one thing that brings me anywhere near him is that I knew enough to leave off?\"\n",
      "\n",
      "He stood up and laid his hand on my shoulder with a laugh. \"Only the irony of it is that I _am_ still painting--since Grindle's doing it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "print(\"Train data:\\n\", train_data[0:50], \"...\", train_data[-50:])\n",
    "print(\"Val data:\\n\", val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fdd32d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "from core import create_dataloader_v1\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length= GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride = GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last = True,\n",
    "    shuffle=True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "val_loader= create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length= GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride = GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last = False,\n",
    "    shuffle= False,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"Validation loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5178d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fa93ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten(0, 1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a842112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # this allows us to calculate the loss on a subset of the data\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd68b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.987583054436577\n",
      "Val loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "# NOTE: seeing odd results when using CPU.\n",
    "#   ex. manual_seed not producing same result\n",
    "#   ex. can't reload a saved model to continue pre-training\n",
    "#   ... falling back to just \"cpu\" for now\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Train loss:\", train_loss)\n",
    "print(\"Val loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37bba3",
   "metadata": {},
   "source": [
    "### 5.2 Training the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cab61e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # calc loss gradients\n",
    "            optimizer.step() # update model weights, given loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Epoch {epoch+1} (Step {global_step:06d}):\"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # disable dropout\n",
    "    with torch.no_grad(): # disable gradient tracking (reduces computational overhead)\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train() # re-enable dropout\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval() # disable dropout\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        max_new_tokens = 50\n",
    "        token_ids = generate_text_simple(model, encoded, max_new_tokens, context_size)\n",
    "\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train() # re-enable dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e2240",
   "metadata": {},
   "source": [
    "Ok! Let's connect it all. We'll use AdamW (weight decay) as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "712d4753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000):Train loss 10.858, Val loss 10.893\n",
      "Epoch 1 (Step 000005):Train loss 10.521, Val loss 10.596\n",
      "Every effort moves you Trump Trump Trump Contracts Trump Contracts Trump Contracts Trump Contracts Immigration Contracts Contracts Contractsetsy Contracts Contracts Contracts investigative Trump Contracts Contractsiques Contracts Patricia Trump spend Contracts Contracts Patricia Trump Contracts Patricia Trump Trump Trump Contracts Patricia Trump Contracts Trump Contracts Contracts Trump Contracts Patricia Trump Contracts Contracts Patricia\n",
      "Epoch 2 (Step 000010):Train loss 10.044, Val loss 10.135\n",
      "Epoch 2 (Step 000015):Train loss 8.923, Val loss 9.112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0004\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      5\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 6\u001b[0m train_losses, val_losses, tokens_seen \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvery effort moves you\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m, in \u001b[0;36mtrain_model_simple\u001b[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m             track_tokens_seen\u001b[38;5;241m.\u001b[39mappend(tokens_seen)\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     25\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_step\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m             )\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mgenerate_and_print_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_losses, val_losses, track_tokens_seen\n",
      "Cell \u001b[0;32mIn[22], line 48\u001b[0m, in \u001b[0;36mgenerate_and_print_sample\u001b[0;34m(model, tokenizer, device, start_context)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     47\u001b[0m     max_new_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 48\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m decoded_text \u001b[38;5;241m=\u001b[39m token_ids_to_text(token_ids, tokenizer)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(decoded_text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/code/baby-llm/core.py:238\u001b[0m, in \u001b[0;36mgenerate_text_simple\u001b[0;34m(model, token_ids, max_new_tokens, context_size)\u001b[0m\n\u001b[1;32m    236\u001b[0m x \u001b[38;5;241m=\u001b[39m token_ids[:, \u001b[38;5;241m-\u001b[39mcontext_size:]\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# during inference, we don't need backprop\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m token \u001b[38;5;241m=\u001b[39m next_token_id(logits)\n\u001b[1;32m    241\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((token_ids, token), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code/baby-llm/core.py:222\u001b[0m, in \u001b[0;36mGPTModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_embedding \u001b[38;5;241m+\u001b[39m pos_embedding\n\u001b[1;32m    220\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_emb(x)\n\u001b[0;32m--> 222\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm(x)\n\u001b[1;32m    225\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_output(x)\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code/baby-llm/core.py:170\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    168\u001b[0m shortcut1 \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    169\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm_1(x)\n\u001b[0;32m--> 170\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_1(x)\n\u001b[1;32m    172\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m shortcut1\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code/baby-llm/core.py:66\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# normalize\u001b[39;00m\n\u001b[1;32m     65\u001b[0m d_k \u001b[38;5;241m=\u001b[39m keys\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_scores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md_k\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# dropout\u001b[39;00m\n\u001b[1;32m     69\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attn_weights)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af2d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, label=\"Validation loss\", linestyle=\"-.\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    # NOTE: I don't see any effect of the below command...\n",
    "    # ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    ax2= ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) # invisible plot, to align ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_seen = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_seen, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1087dd",
   "metadata": {},
   "source": [
    "### 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d3f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (tf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer_norm): LayerNorm()\n",
       "  (linear_output): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\") # cpu is sufficient for inference\n",
    "model.eval() # disable random components like dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b59a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model,\n",
    "    text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba2e1a",
   "metadata": {},
   "source": [
    "The above output is currently deterministic due to how we always select the most probable next word. \n",
    "\n",
    "Let's try adjusting our strategy for choosing the next word:\n",
    "\n",
    "1. choose from the probability distribution\n",
    "2. use temperature scaling (scale the logits) to adjust randomness\n",
    "  - low temp = less randomness (more likely to choose the most probable word)\n",
    "  - high temp = more randomness (smooths the distribution)\n",
    "3. top-k sampling: only consider the top k most probable words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74971d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43727480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next word: forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=-1)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(\"next word:\", inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada3813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next word: forward\n"
     ]
    }
   ],
   "source": [
    "# to do sampling, we replace argmax with multi-nomial sampling\n",
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(\"next word:\", inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer    : 73\n",
      "every     : 0\n",
      "effort    : 0\n",
      "forward   : 582\n",
      "inches    : 2\n",
      "moves     : 0\n",
      "pizza     : 0\n",
      "toward    : 343\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    # bincount gives the frequency of each value\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{inverse_vocab[i]:<10}: {freq.item()}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf6ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Probability')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=-1)\n",
    "\n",
    "temperatures = [1, 0.1, 5.]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, t) for t in temperatures]\n",
    "\n",
    "# Graph the scaled probas\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "for i, t in enumerate(temperatures):\n",
    "    ax.bar(x + i*bar_width, scaled_probas[i], bar_width, label=f\"T = {t}\")\n",
    "ax.set_xticks(range(len(vocab)))\n",
    "ax.set_xticklabels(inverse_vocab.values(), rotation=90)\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_ylabel(\"Probability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2661a5",
   "metadata": {},
   "source": [
    "_Exercise 5.1:Use the print_sampled_tokens function to print the sampling frequencies of the softmax probabilities scaled with the temperatures shown in figure 5.14._\n",
    "\n",
    "_How often is the word pizza sampled in each case? Can you think of a faster and more accurate way to determine how often the word pizza is sampled?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd74f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature = 1 ...\n",
      "closer    : 73\n",
      "every     : 0\n",
      "effort    : 0\n",
      "forward   : 582\n",
      "inches    : 2\n",
      "moves     : 0\n",
      "pizza     : 0\n",
      "toward    : 343\n",
      "Temperature = 0.1 ...\n",
      "closer    : 0\n",
      "every     : 0\n",
      "effort    : 0\n",
      "forward   : 985\n",
      "inches    : 0\n",
      "moves     : 0\n",
      "pizza     : 0\n",
      "toward    : 15\n",
      "Temperature = 5.0 ...\n",
      "closer    : 165\n",
      "every     : 75\n",
      "effort    : 42\n",
      "forward   : 239\n",
      "inches    : 71\n",
      "moves     : 46\n",
      "pizza     : 32\n",
      "toward    : 227\n",
      "you       : 103\n",
      "Temperature = 1.0, p = 0.000, expected pizza count: 0\n",
      "Temperature = 0.1, p = 0.000, expected pizza count: 0\n",
      "Temperature = 5.0, p = 0.043, expected pizza count: 43\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(temperatures):\n",
    "    print(f\"Temperature = {t} ...\")\n",
    "    print_sampled_tokens(scaled_probas[i])\n",
    "\n",
    "# How often is the word pizza sampled in each case?\n",
    "# t=1     pizza =0\n",
    "# t=0.1   pizza = 0\n",
    "# t=5     pizza = 32\n",
    "\n",
    "# faster and more accurate approach?\n",
    "# -> we can calculate the expected count of the word pizza based\n",
    "#   on the probability distribution\n",
    "for i, t in enumerate(temperatures):\n",
    "    pizza_idx = vocab[\"pizza\"]\n",
    "    p = scaled_probas[i][pizza_idx]\n",
    "    expected = p * 1000\n",
    "    print(f\"Temperature = {t:.1f}, p = {p:.3f}, expected pizza count: {expected:.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e590e",
   "metadata": {},
   "source": [
    "In order to constrain the randomness, let's try **top-K sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87919dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_mask(logits, k=3, is_batch=False):\n",
    "    top_values, _ = torch.topk(logits, k)\n",
    "    min_value = top_values[:, -1] if is_batch else top_values[-1]\n",
    "    new_logits = torch.where(\n",
    "        condition=logits < min_value,\n",
    "        input= torch.tensor(-1 * torch.inf).to(logits.device),\n",
    "        other=logits,\n",
    "    )\n",
    "    return new_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
      "         1.7900])\n",
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "tensor([  -inf,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "print(next_token_logits)\n",
    "print(top_k_mask(next_token_logits, k=3))\n",
    "print(top_k_mask(next_token_logits, k=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "top_k_probas = torch.softmax(top_k_mask(next_token_logits, k=3), dim=-1)\n",
    "print(top_k_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1679b",
   "metadata": {},
   "source": [
    "Here's a modified text generation with more diverse outputs.\n",
    "\n",
    "We incorporate the multinomial sampling, temperature scaling, and top-k sampling strategies.\n",
    "\n",
    "We also add an early exit condition if we generate an \"end-of-sequence\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b83f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified text generation with more diverse outputs\n",
    "def generate(model, token_ids, max_new_tokens, context_size, temperature=0.0, top_k: int|None=None, eos_id=None):\n",
    "    for i in range(max_new_tokens):\n",
    "        # all samples in batch .. most-recent `<= context_size` tokens\n",
    "        x = token_ids[:, -context_size:]\n",
    "        with torch.no_grad():  # during inference, we don't need backprop\n",
    "            logits = model(x)\n",
    "\n",
    "        token = next_token_id_v2(logits, temperature=temperature, top_k=top_k)\n",
    "        token_ids = torch.cat((token_ids, token), dim=1)\n",
    "        if token == eos_id:\n",
    "            # exit early if we encounter the end-of-sequence token\n",
    "            break\n",
    "\n",
    "    return token_ids\n",
    "\n",
    "\n",
    "def next_token_id_v2(batch_logits, temperature=0.1, top_k: int|None=3):\n",
    "    \"\"\"Given batched model output, return next token's id\"\"\"\n",
    "    # for each sample in batch, select logits for last token\n",
    "    logits = batch_logits[:, -1, :]\n",
    "\n",
    "    if top_k is not None:\n",
    "        # mask logits to only keep top-k values\n",
    "        logits = top_k_mask(logits, k=top_k, is_batch=True)\n",
    "\n",
    "    if temperature > 0.0:\n",
    "        # use temperature to scale logits\n",
    "        logits = logits / temperature\n",
    "\n",
    "        # softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # choose token id using multinoimal sampling\n",
    "        token_id = torch.multinomial(probas, num_samples=1)\n",
    "    else:\n",
    "        token_id = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    return token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a32d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Output text:\n",
      " Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model,\n",
    "    text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e7d1a",
   "metadata": {},
   "source": [
    "_Exercise 5.2_\n",
    "\n",
    "_Play around with different temperatures and top-k settings. Based on your observations, can you think of applications where lower temperature and top-k settings are desired? Likewise, can you think of applications where higher temperature and top-k settings are preferred?_\n",
    "\n",
    "Lower temperature and top-k would be desireable if you need a more deterministic output\n",
    "For example, suppose you want to write in a very strict format. This could also include very specific formatting like code generation.\n",
    "\n",
    "Higher temperature and top-k would be desirable if you want more randomness.\n",
    "For example, creative writing, or brainstorming session._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee74fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature = 0.0, top_k = 1\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.0, top_k = 3\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.0, top_k = 5\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.0, top_k = 10\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.0, top_k = None\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.1, top_k = 1\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.1, top_k = 3\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.1, top_k = 5\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.1, top_k = 10\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.1, top_k = None\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.5, top_k = 1\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.5, top_k = 3\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.5, top_k = 5\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.5, top_k = 10\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 0.5, top_k = None\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.0, top_k = 1\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.0, top_k = 3\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.0, top_k = 5\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.0, top_k = 10\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.0, top_k = None\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.5, top_k = 1\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.5, top_k = 3\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.5, top_k = 5\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.5, top_k = 10\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 1.5, top_k = None\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 2.0, top_k = 1\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 2.0, top_k = 3\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 2.0, top_k = 5\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 2.0, top_k = 10\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n",
      "Temperature = 2.0, top_k = None\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1]])\n",
      "tensor([[1]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13]])\n",
      "tensor([[314]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314]])\n",
      "tensor([[340]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340]])\n",
      "tensor([[257]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257]])\n",
      "tensor([[11]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11]])\n",
      "tensor([[13]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13]])\n",
      "tensor([[465]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465]])\n",
      "tensor([[502]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366]])\n",
      "tensor([[616]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616]])\n",
      "tensor([[438]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438]])\n",
      "tensor([[366]])\n",
      "tensor([[6109, 3626, 6100,  345,    1,    1,   13,  314,  340,  257,   11,   13,\n",
      "          465,  502,  366,  616,  438,  366]])\n",
      "tensor([[198]])\n",
      "Every effort moves you\"\". I it a,. his me \" my-- \"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [0.0, 0.1, 0.5, 1.0, 1.5, 2.0]:\n",
    "    for top_k in [1, 3, 5, 10, None]:\n",
    "        print(f\"Temperature = {t}, top_k = {top_k}\")\n",
    "        torch.manual_seed(123)\n",
    "        token_ids = generate(\n",
    "    model,\n",
    "    text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4,\n",
    ")\n",
    "        text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(text)\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741403e",
   "metadata": {},
   "source": [
    "_Exercise 5.3_\n",
    "\n",
    "_What are the different combinations of settings for the generate function to force deterministic behavior, that is, disabling the random sampling such that it always produces the same outputs similar to the generate_simple function?_\n",
    "\n",
    "- temperature = 0 forces determinism (falls back to argmax, so always chooses the most probable word)\n",
    "  - book says \"Setting to top_k=None and applying no temperature scaling\".. but I think temp=0 alone is enough\n",
    "- top_k sampling with k = 1 also forces determinism (always chooses the most probable word), regardless of temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e82831",
   "metadata": {},
   "source": [
    "### 5.4 Saving and Loading model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic approach is pretty straightforward!\n",
    "model_state = model.state_dict()\n",
    "torch.save(model_state, \"model.pth\")\n",
    "\n",
    "# If we want to continue pretraining later, we can save the optimizer state\n",
    "optimizer_state = optimizer.state_dict()\n",
    "torch.save(optimizer_state, \"optimizer.pth\")\n",
    "\n",
    "# We can also save multiple at once!\n",
    "torch.save(\n",
    "    {\n",
    "    \"model_state_dict\": model_state,\n",
    "    \"optimizer_state_dict\": optimizer_state,\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c298b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (tf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (layer_norm_1): LayerNorm()\n",
       "      (mha): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm_2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_layer_norm): LayerNorm()\n",
       "  (linear_output): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# we load the weights AND we also map them to the appropriate device (cuda, cpu, etc)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "# training off, eval (inference) on!\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3f158",
   "metadata": {},
   "source": [
    "Now let's restore the model and optimizer state..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train(); # we can resume pre-training.. the optimizer is also is the right state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877b013",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m model2, optimizer2\u001b[38;5;241m=\u001b[39m load_model_for_training(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_and_optimizer.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# 1 more\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvery effort moves you\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m, in \u001b[0;36mtrain_model_simple\u001b[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_batch, target_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_loss_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# calc loss gradients\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# update model weights, given loss gradients\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m, in \u001b[0;36mcalc_loss_batch\u001b[0;34m(input_batch, target_batch, model, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m input_batch \u001b[38;5;241m=\u001b[39m input_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m target_batch \u001b[38;5;241m=\u001b[39m target_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(logits\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m), target_batch\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code/baby-llm/core.py:214\u001b[0m, in \u001b[0;36mGPTModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    211\u001b[0m batch_size, context_length \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# `tok_emb` should be initialized randomly, so we just need to do the lookup\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m tok_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# `pos_emb` should be initialized based on ordered position\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# TODO: what does it mean that we call this during the forward() step?\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m#       intuitively, I think of pos_emb as initialized at start and then updated at each step\u001b[39;00m\n\u001b[1;32m    218\u001b[0m pos_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb(torch\u001b[38;5;241m.\u001b[39marange(context_length, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice))\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/baby-llm/.venv/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Exercise 5.4\n",
    "After saving the weights, load the model and optimizer in a new Python session or Jupyter notebook file\n",
    "and continue pretraining it for one more epoch using the train_model_simple function.\n",
    "\n",
    "- load the model and optimizer\n",
    "- num_epochs=1\n",
    "- if we were in another session, we'd also need to bring along the train_loader and val_loader\n",
    "\"\"\"\n",
    "\n",
    "def load_model_for_training(path=\"model_and_optimizer.pth\"):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model = GPTModel(GPT_CONFIG_124M)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    model.train()\n",
    "    return model, optimizer\n",
    "\n",
    "model2, optimizer2= load_model_for_training(\"model_and_optimizer.pth\")\n",
    "num_epochs = 1 # 1 more\n",
    "train_model_simple(\n",
    "    model2, train_loader, val_loader, optimizer2, device,\n",
    "    num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e85a3a",
   "metadata": {},
   "source": [
    "### 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24990193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x160e9f8b0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08634ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<00:00, 30.4kiB/s]\n",
      "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:00<00:00, 1.48MiB/s]\n",
      "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.0/90.0 [00:00<00:00, 30.7kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498M/498M [05:15<00:00, 1.58MiB/s] \n",
      "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.21k/5.21k [00:00<00:00, 1.20MiB/s]\n",
      "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471k/471k [00:00<00:00, 1.50MiB/s]\n",
      "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 1.53MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c29002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Param keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "Param wte:  [[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dims:  (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Param keys:\", params.keys())\n",
    "print(\"Param wte: \", params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dims: \", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10297696",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_heads\": 12, \"n_layers\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_heads\": 16, \"n_layers\": 24},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_heads\": 20, \"n_layers\": 36},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_heads\": 25, \"n_layers\": 48},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff46d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpt2_model(model_name = \"gpt2-small (124M)\"):\n",
    "    model_config = GPT_CONFIG_124M.copy()\n",
    "    model_config.update(model_configs[model_name])\n",
    "    # we had used 256 for faster local training\n",
    "    model_config.update({\"context_length\": 1024})\n",
    "    # GPT2 had bias vectors in qkv\n",
    "    model_config.update({\"qkv_bias\": True})\n",
    "\n",
    "    model = GPTModel(model_config)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ffa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Now we need to load weights.\n",
    "\n",
    "# # First let's make a method to assign weights\n",
    "# # It can sanity check we don't make silly mistakes\n",
    "# # NOTE: This is variant of the book code that overwrites in place,\n",
    "# # to be more concise in the load_weights_into_gpt fn below\n",
    "# def assign(left, right: np.ndarray):\n",
    "#     if left.shape != right.shape:\n",
    "#         raise ValueError(f\"Shape mistmatch {left.shape} != {right.shape}\")\n",
    "#     left.data = torch.tensor(right)\n",
    "\n",
    "# def load_weights_into_gpt(gpt: GPTModel, params):\n",
    "#     # position and token embeddings\n",
    "#     assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "#     assign(gpt.token_emb.weight, params[\"wte\"])\n",
    "\n",
    "#     # tranformer layers\n",
    "#     for b in range(len(params[\"blocks\"])):\n",
    "#         ## multi-head attention\n",
    "#         w_q, w_k, w_v = np.split(\n",
    "#             (params[\"blocks\"][b][\"attn\"][\"c_attn\"])['w'], 3, axis=-1)\n",
    "#         assign(gpt.tf_blocks[b].mha.W_query.weight, w_q.T)\n",
    "#         assign(gpt.tf_blocks[b].mha.W_key.weight, w_k.T)\n",
    "#         assign(gpt.tf_blocks[b].mha.W_value.weight, w_v.T)\n",
    "\n",
    "#         b_q, b_k, b_v = np.split(\n",
    "#             (params[\"blocks\"][b][\"attn\"][\"c_attn\"])['b'], 3, axis=-1\n",
    "#         )\n",
    "#         assign(gpt.tf_blocks[b].mha.W_query.bias, b_q)\n",
    "#         assign(gpt.tf_blocks[b].mha.W_key.bias, b_k)\n",
    "#         assign(gpt.tf_blocks[b].mha.W_value.bias, b_v)\n",
    "\n",
    "#         assign(gpt.tf_blocks[b].mha.out_proj.weight,  params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "#         assign(gpt.tf_blocks[b].mha.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "\n",
    "#         ## feed forward\n",
    "#         assign(gpt.tf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "#         assign(gpt.tf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "\n",
    "#         assign(gpt.tf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "#         assign(gpt.tf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "#         # layer norms\n",
    "#         assign(gpt.tf_blocks[b].layer_norm_1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "#         assign(gpt.tf_blocks[b].layer_norm_1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "\n",
    "#         assign(gpt.tf_blocks[b].layer_norm_2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "#         assign(gpt.tf_blocks[b].layer_norm_2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "#     assign(gpt.final_layer_norm.scale, params[\"g\"])\n",
    "#     assign(gpt.final_layer_norm.shift, params[\"b\"])\n",
    "#     assign(gpt.linear_output.weight, params[\"wte\"]) # weight tied to the input token embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                          \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):           #1\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.token_emb.weight = assign(gpt.token_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):     #2\n",
    "        q_w, k_w, v_w = np.split(                            #3\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.tf_blocks[b].mha.W_query.weight = assign(\n",
    "            gpt.tf_blocks[b].mha.W_query.weight, q_w.T)\n",
    "        gpt.tf_blocks[b].mha.W_key.weight = assign(\n",
    "            gpt.tf_blocks[b].mha.W_key.weight, k_w.T)\n",
    "        gpt.tf_blocks[b].mha.W_value.weight = assign(\n",
    "            gpt.tf_blocks[b].mha.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.tf_blocks[b].mha.W_query.bias = assign(\n",
    "            gpt.tf_blocks[b].mha.W_query.bias, q_b)\n",
    "        gpt.tf_blocks[b].mha.W_key.bias = assign(\n",
    "            gpt.tf_blocks[b].mha.W_key.bias, k_b)\n",
    "        gpt.tf_blocks[b].mha.W_value.bias = assign(\n",
    "            gpt.tf_blocks[b].mha.W_value.bias, v_b)\n",
    "\n",
    "        gpt.tf_blocks[b].mha.out_proj.weight = assign(\n",
    "            gpt.tf_blocks[b].mha.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.tf_blocks[b].mha.out_proj.bias = assign(\n",
    "            gpt.tf_blocks[b].mha.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.tf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.tf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.tf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.tf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.tf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.tf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.tf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.tf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.tf_blocks[b].layer_norm_1.scale = assign(\n",
    "            gpt.tf_blocks[b].layer_norm_1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.tf_blocks[b].layer_norm_1.shift = assign(\n",
    "            gpt.tf_blocks[b].layer_norm_1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.tf_blocks[b].layer_norm_2.scale = assign(\n",
    "            gpt.tf_blocks[b].layer_norm_2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.tf_blocks[b].layer_norm_2.shift = assign(\n",
    "            gpt.tf_blocks[b].layer_norm_2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_layer_norm.scale = assign(gpt.final_layer_norm.scale, params[\"g\"])\n",
    "    gpt.final_layer_norm.shift = assign(gpt.final_layer_norm.shift, params[\"b\"])\n",
    "    gpt.linear_output.weight = assign(gpt.linear_output.weight, params[\"wte\"])    #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = create_gpt2_model(\"gpt2-small (124M)\")\n",
    "gpt.eval(); # TIL can use ; to suppress output in Jupyter\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc817a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you not\" an I it a ' is at' \" or for \" by at was- on, on A ( the one\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "max_new_tokens=25\n",
    "context_size=1024\n",
    "token_ids = generate(\n",
    "    gpt,\n",
    "    text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens,\n",
    "    context_size,\n",
    "    top_k=50,\n",
    "    temperature=1.5,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b704b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
